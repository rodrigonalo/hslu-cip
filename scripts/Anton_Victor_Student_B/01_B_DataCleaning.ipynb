{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files into DataFrames\n",
    "# df from Markets Business Insiders\n",
    "aex_df = pd.read_csv('../data/raw_data/aex_stock_data.csv')\n",
    "bel_20_df = pd.read_csv('../data/raw_data/bel_20_stock_data.csv')\n",
    "cac_40_df = pd.read_csv('../data/raw_data/cac_40_stock_data.csv')\n",
    "#iseq_20_df = pd.read_csv('../data/raw_data/iseq_20_stock_data.csv')\n",
    "obx_df = pd.read_csv('../data/raw_data/obx_stock_data.csv')\n",
    "osebx_df = pd.read_csv('../data/raw_data/osebx_stock_data.csv')\n",
    "psi_20_df = pd.read_csv('../data/raw_data/psi_20_stock_data.csv')\n",
    "\n",
    "# df from Wikipedia\n",
    "aex_df_wiki = pd.read_csv('../data/raw_data/aex_wikipedia_data.csv')\n",
    "bel_20_df_wiki = pd.read_csv('../data/raw_data/bel_20_wikipedia_data.csv')\n",
    "cac_40_df_wiki = pd.read_csv('../data/raw_data/cac_40_wikipedia_data.csv')\n",
    "#iseq_20_df_wiki = pd.read_csv('../data/raw_data/iseq_20_wikipedia_data.csv')\n",
    "obx_df_wiki = pd.read_csv('../data/raw_data/obx_wikipedia_data.csv')\n",
    "osebx_df_wiki = pd.read_csv('../data/raw_data/osebx_wikipedia_data.csv')\n",
    "psi_20_df_wiki = pd.read_csv('../data/raw_data/psi_20_wikipedia_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'Index Name' column for each DataFrame\n",
    "aex_df['Index'] = 'AEX'\n",
    "bel_20_df['Index'] = 'BEL_20'\n",
    "cac_40_df['Index'] = 'CAC_40'\n",
    "#iseq_20_df['Index Name'] = 'ISEQ_20'\n",
    "obx_df['Index'] = 'OBX'\n",
    "osebx_df['Index'] = 'OSEBX'\n",
    "psi_20_df['Index'] = 'PSI_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEX</td>\n",
       "      <td>ABN Amro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEX</td>\n",
       "      <td>Adyen B.V. Parts Sociales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEX</td>\n",
       "      <td>Ahold Delhaize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEX</td>\n",
       "      <td>Akzo Nobel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEX</td>\n",
       "      <td>ArcelorMittal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>PSI_20</td>\n",
       "      <td>REN - Redes Energeticas Nacionais SGPS, SAShs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>PSI_20</td>\n",
       "      <td>Sociedade de Investimento e Gestao SGPS SA SEMAPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>PSI_20</td>\n",
       "      <td>Sonae SGPS SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>PSI_20</td>\n",
       "      <td>Sonaecom SGPS SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>PSI_20</td>\n",
       "      <td>The Navigator Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index                                            Company\n",
       "0       AEX                                           ABN Amro\n",
       "1       AEX                          Adyen B.V. Parts Sociales\n",
       "2       AEX                                     Ahold Delhaize\n",
       "3       AEX                                         Akzo Nobel\n",
       "4       AEX                                      ArcelorMittal\n",
       "..      ...                                                ...\n",
       "147  PSI_20      REN - Redes Energeticas Nacionais SGPS, SAShs\n",
       "148  PSI_20  Sociedade de Investimento e Gestao SGPS SA SEMAPA\n",
       "149  PSI_20                                      Sonae SGPS SA\n",
       "150  PSI_20                                   Sonaecom SGPS SA\n",
       "151  PSI_20                              The Navigator Company\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "df = pd.concat([aex_df, bel_20_df, cac_40_df, obx_df, osebx_df, psi_20_df])\n",
    "\n",
    "# Reset the index to create a new unique primary key for each row\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select only the 'Index Name' and 'Name' columns\n",
    "df = df[['Index', 'Name']]\n",
    "df.rename(columns={'Name': 'Company'}, inplace=True)\n",
    "# Display the first 40 rows of the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file in the 'data' folder\n",
    "csv_filename = 'combined_stock_data.csv'\n",
    "df.to_csv(f'../data/raw_data/{csv_filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Index           Company Ticker\n",
      "0       AEX             Adyen  ADYEN\n",
      "1       AEX             Aegon    AGN\n",
      "2       AEX    Ahold Delhaize     AD\n",
      "3       AEX         AkzoNobel   AKZA\n",
      "4       AEX     ArcelorMittal     MT\n",
      "..      ...               ...    ...\n",
      "295  PSI_20      Galp Energia   GALP\n",
      "296  PSI_20           Ibersol    IBS\n",
      "297  PSI_20  Jerónimo Martins    JMT\n",
      "298  PSI_20        Mota-Engil    EGL\n",
      "299  PSI_20               NOS    NOS\n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrames list with their corresponding index names\n",
    "df_to_clean = {\n",
    "    'AEX': aex_df_wiki,\n",
    "    'BEL_20': bel_20_df_wiki,\n",
    "    'CAC_40': cac_40_df_wiki,\n",
    "    'OBX': obx_df_wiki,\n",
    "    'OSEBX': osebx_df_wiki,\n",
    "    'PSI_20': psi_20_df_wiki\n",
    "}\n",
    "\n",
    "# Prepare the dataframes\n",
    "for index_name, df in df_to_clean.items():\n",
    "    # Standardize column names\n",
    "    if 'Ticker symbol' in df.columns:\n",
    "        df.rename(columns={'Ticker symbol': 'Ticker'}, inplace=True)\n",
    "    if 'Name' in df.columns and index_name == 'OSEBX':\n",
    "        df.rename(columns={'Name': 'Company'}, inplace=True)\n",
    "    \n",
    "    # Clean the 'Ticker' column\n",
    "    df['Ticker'] = df['Ticker'].apply(lambda ticker: re.sub(r'.*:', '', ticker).strip())\n",
    "    \n",
    "    # Add the 'Index' column\n",
    "    df['Index'] = index_name\n",
    "\n",
    "# Combine all the prepared dataframes into one\n",
    "df_wiki = pd.concat(df_to_clean.values())\n",
    "\n",
    "# Select only the required columns and remove duplicates\n",
    "df_wiki = df_wiki[['Index', 'Company', 'Ticker']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Function to clean company names\n",
    "def clean_company_name(name):\n",
    "    name = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', name)\n",
    "    name = name.replace('...', ' ')\n",
    "    name = ' '.join(name.split())\n",
    "    return name\n",
    "\n",
    "# Apply the cleaning function to the 'Company' column\n",
    "df_wiki['Company'] = df_wiki['Company'].apply(clean_company_name)\n",
    "\n",
    "# Export the final dataframe to a CSV file\n",
    "csv_filename = 'combined_wiki_data.csv'\n",
    "df_wiki.to_csv(f'../data/raw_data/{csv_filename}', index=False)\n",
    "\n",
    "# Display the first few rows of the final dataframe to verify\n",
    "print(df_wiki.head(300))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find similarity between two strings\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# Read data from both datasets\n",
    "data1 = pd.read_csv('../data/raw_data/combined_wiki_data.csv')\n",
    "data2 = pd.read_csv('../data/raw_data/combined_stock_data.csv')\n",
    "combined_wiki_data = pd.read_csv('../data/raw_data/combined_wiki_data.csv')\n",
    "\n",
    "company_mapping = {}\n",
    "\n",
    "# Iterate over the companies in data1\n",
    "for company1 in data1['Company']:\n",
    "    max_similarity = 0\n",
    "    mapped_company = \"\"\n",
    "    for company2 in data2['Company']:\n",
    "        similarity = similar(company1, company2)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            mapped_company = company2\n",
    "    company_mapping[company1] = mapped_company\n",
    "    \n",
    "# Iterate over the companies in data2\n",
    "for company2 in data2['Company']:\n",
    "    max_similarity = 0\n",
    "    mapped_company = \"\"\n",
    "    for company1 in data1['Company']:\n",
    "        similarity = similar(company1, company2)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            mapped_company = company1\n",
    "    company_mapping[company2] = mapped_company\n",
    "    \n",
    "\n",
    "# Apply the mapping \n",
    "data1['Company'] = data1['Company'].map(company_mapping)\n",
    "data2['Company'] = data2['Company'].map(company_mapping)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "#data1.to_csv('../data/raw_data/data1_mapped.csv', index=False)\n",
    "#data2.to_csv('../data/raw_data/data2_mapped.csv', index=False)\n",
    "\n",
    "# Merge the wiki data to get the tickers\n",
    "combined_final_data = data2.merge(\n",
    "    combined_wiki_data[['Company', 'Ticker']],\n",
    "    on='Company',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "missing_tickers = combined_final_data[combined_final_data['Ticker'].isna()]\n",
    "missing_tickers.head()\n",
    "\n",
    "combined_final_data = combined_final_data.drop_duplicates(subset=['Index', 'Company', 'Ticker'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "csv_filename = 'combined_final_data.csv'\n",
    "combined_final_data.to_csv(f'../data/clean_data/{csv_filename}', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
